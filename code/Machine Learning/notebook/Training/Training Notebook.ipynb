{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2609027,"sourceType":"datasetVersion","datasetId":5857}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T06:03:45.959694Z","iopub.execute_input":"2024-04-24T06:03:45.960016Z","iopub.status.idle":"2024-04-24T06:04:06.642121Z","shell.execute_reply.started":"2024-04-24T06:03:45.959989Z","shell.execute_reply":"2024-04-24T06:04:06.641276Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-24 06:03:49.404018: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-24 06:03:49.404145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-24 06:03:49.684964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Training'\ntest_data_dir = '/kaggle/input/fruits/fruits-360-original-size/fruits-360-original-size/Test'","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:04:06.647269Z","iopub.execute_input":"2024-04-24T06:04:06.647535Z","iopub.status.idle":"2024-04-24T06:04:06.655345Z","shell.execute_reply.started":"2024-04-24T06:04:06.647511Z","shell.execute_reply":"2024-04-24T06:04:06.650912Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_width, img_height = 224, 224\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:04:06.657444Z","iopub.execute_input":"2024-04-24T06:04:06.658532Z","iopub.status.idle":"2024-04-24T06:04:06.696918Z","shell.execute_reply.started":"2024-04-24T06:04:06.658504Z","shell.execute_reply":"2024-04-24T06:04:06.696059Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:04:07.172154Z","iopub.execute_input":"2024-04-24T06:04:07.172733Z","iopub.status.idle":"2024-04-24T06:04:07.177238Z","shell.execute_reply.started":"2024-04-24T06:04:07.172703Z","shell.execute_reply":"2024-04-24T06:04:07.176153Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:04:13.627763Z","iopub.execute_input":"2024-04-24T06:04:13.628195Z","iopub.status.idle":"2024-04-24T06:04:13.632699Z","shell.execute_reply.started":"2024-04-24T06:04:13.628164Z","shell.execute_reply":"2024-04-24T06:04:13.631762Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:04:20.753555Z","iopub.execute_input":"2024-04-24T06:04:20.753899Z","iopub.status.idle":"2024-04-24T06:04:21.626494Z","shell.execute_reply.started":"2024-04-24T06:04:20.753872Z","shell.execute_reply":"2024-04-24T06:04:21.625527Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 6231 images belonging to 24 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:05:00.755659Z","iopub.execute_input":"2024-04-24T06:05:00.756291Z","iopub.status.idle":"2024-04-24T06:05:01.430359Z","shell.execute_reply.started":"2024-04-24T06:05:00.756258Z","shell.execute_reply":"2024-04-24T06:05:01.429442Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 3110 images belonging to 24 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:05:08.963017Z","iopub.execute_input":"2024-04-24T06:05:08.963845Z","iopub.status.idle":"2024-04-24T06:05:11.227982Z","shell.execute_reply.started":"2024-04-24T06:05:08.963812Z","shell.execute_reply":"2024-04-24T06:05:11.227206Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:05:17.115162Z","iopub.execute_input":"2024-04-24T06:05:17.115987Z","iopub.status.idle":"2024-04-24T06:05:17.123635Z","shell.execute_reply.started":"2024-04-24T06:05:17.115954Z","shell.execute_reply":"2024-04-24T06:05:17.122774Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n    base_model,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dense(256, activation='relu'),\n    keras.layers.Dense(train_generator.num_classes, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:05:23.930515Z","iopub.execute_input":"2024-04-24T06:05:23.931263Z","iopub.status.idle":"2024-04-24T06:05:23.939863Z","shell.execute_reply.started":"2024-04-24T06:05:23.931231Z","shell.execute_reply":"2024-04-24T06:05:23.938999Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:05:30.636168Z","iopub.execute_input":"2024-04-24T06:05:30.636799Z","iopub.status.idle":"2024-04-24T06:05:30.651680Z","shell.execute_reply.started":"2024-04-24T06:05:30.636769Z","shell.execute_reply":"2024-04-24T06:05:30.650851Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nmodel.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    epochs=epochs,\n    validation_data=test_generator,\n    validation_steps=test_generator.samples // batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T06:05:37.749456Z","iopub.execute_input":"2024-04-24T06:05:37.750294Z","iopub.status.idle":"2024-04-24T06:15:47.192151Z","shell.execute_reply.started":"2024-04-24T06:05:37.750261Z","shell.execute_reply":"2024-04-24T06:15:47.191159Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/194\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:30\u001b[0m 21s/step - accuracy: 0.0938 - loss: 3.5272","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1713938760.363925     102 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1713938760.399112     102 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m110/194\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 751ms/step - accuracy: 0.6892 - loss: 1.1465","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1713938842.203012     102 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.7779 - loss: 0.8229","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1713938902.620608     101 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 913ms/step - accuracy: 0.7786 - loss: 0.8203 - val_accuracy: 0.9948 - val_loss: 0.0397\nEpoch 2/10\n\u001b[1m  1/194\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0217","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 1.0000 - val_loss: 0.0731\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1713938940.943022     100 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 503ms/step - accuracy: 0.9926 - loss: 0.0363 - val_accuracy: 0.9932 - val_loss: 0.0307\nEpoch 4/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165us/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0300\nEpoch 5/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 505ms/step - accuracy: 0.9973 - loss: 0.0152 - val_accuracy: 0.9965 - val_loss: 0.0179\nEpoch 6/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158us/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0033\nEpoch 7/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 505ms/step - accuracy: 0.9991 - loss: 0.0077 - val_accuracy: 0.9994 - val_loss: 0.0050\nEpoch 8/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157us/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 1.0388e-04\nEpoch 9/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 512ms/step - accuracy: 0.9996 - loss: 0.0043 - val_accuracy: 0.9994 - val_loss: 0.0056\nEpoch 10/10\n\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164us/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0074\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x783710387dc0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}